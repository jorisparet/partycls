<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>partycls.feature_scaling API documentation</title>
<meta name="description" content="Feature scaling techniques, to be performed on a dataset stored in a numpy
array." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block}.homelink img{max-width:150px;margin-left:auto;margin-right:auto;margin-bottom:.3em}</style>
<link rel="shortcut icon" href="https://raw.githubusercontent.com/jorisparet/partycls/master/logo/favicon.svg"/>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>partycls.feature_scaling</code></h1>
</header>
<section id="section-intro">
<p>Feature scaling techniques, to be performed on a dataset stored in a numpy
array.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Feature scaling techniques, to be performed on a dataset stored in a numpy
array.
&#34;&#34;&#34;

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import RobustScaler

__all__ = [&#39;ZScore&#39;, &#39;MinMax&#39;, &#39;MaxAbs&#39;, &#39;Robust&#39;]


class ZScore(StandardScaler):

    symbol = &#39;zscore&#39;
    full_name = &#39;Z-Score&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Standardize features by removing the mean and scaling to unit variance.

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)


class MinMax(MinMaxScaler):

    symbol = &#39;minmax&#39;
    full_name = &#39;Min-Max&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Transform features by scaling each feature to a given range (default 
        is [0,1]).

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)


class MaxAbs(MaxAbsScaler):

    symbol = &#39;maxabs&#39;
    full_name = &#39;Max-Abs&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Scale each feature by its maximum absolute value.

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)


class Robust(RobustScaler):

    symbol = &#39;robust&#39;
    full_name = &#39;Robust&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Scale features using statistics that are robust to outliers.

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="partycls.feature_scaling.MaxAbs"><code class="flex name class">
<span>class <span class="ident">MaxAbs</span></span>
<span>(</span><span>*, copy=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Scale each feature by its maximum absolute value.</p>
<p>This estimator scales and translates each feature individually such
that the maximal absolute value of each feature in the
training set will be 1.0. It does not shift/center the data, and
thus does not destroy any sparsity.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>copy</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>Set to False to perform inplace scaling and avoid a copy (if the input
is already a numpy array).</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>scale_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>
<p>Per feature relative scaling of the data.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>scale_</em> attribute.</p>
</div>
</dd>
<dt><strong><code>max_abs_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>Per feature maximum absolute value.</dd>
<dt><strong><code>n_samples_seen_</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of samples processed by the estimator. Will be reset on
new calls to fit, but increments across <code>partial_fit</code> calls.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.preprocessing import MaxAbsScaler
&gt;&gt;&gt; X = [[ 1., -1.,  2.],
...      [ 2.,  0.,  0.],
...      [ 0.,  1., -1.]]
&gt;&gt;&gt; transformer = MaxAbsScaler().fit(X)
&gt;&gt;&gt; transformer
MaxAbsScaler()
&gt;&gt;&gt; transformer.transform(X)
array([[ 0.5, -1. ,  1. ],
       [ 1. ,  0. ,  0. ],
       [ 0. ,  1. , -0.5]])
</code></pre>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>maxabs_scale</code></dt>
<dd>Equivalent function without the estimator API.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see :ref:<code>examples/preprocessing/plot_all_scaling.py
&lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MaxAbs(MaxAbsScaler):

    symbol = &#39;maxabs&#39;
    full_name = &#39;Max-Abs&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Scale each feature by its maximum absolute value.

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.preprocessing._data.MaxAbsScaler</li>
<li>sklearn.base.TransformerMixin</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="partycls.feature_scaling.MaxAbs.full_name"><code class="name">var <span class="ident">full_name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="partycls.feature_scaling.MaxAbs.symbol"><code class="name">var <span class="ident">symbol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="partycls.feature_scaling.MaxAbs.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Scale each feature by its maximum absolute value.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Original features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Scaled features.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, X):
    &#34;&#34;&#34;
    Scale each feature by its maximum absolute value.

    Parameters
    ----------
    X : numpy.ndarray
        Original features.

    Returns
    -------
    numpy.ndarray
        Scaled features.

    &#34;&#34;&#34;
    return self.fit_transform(X)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="partycls.feature_scaling.MinMax"><code class="flex name class">
<span>class <span class="ident">MinMax</span></span>
<span>(</span><span>feature_range=(0, 1), *, copy=True, clip=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform features by scaling each feature to a given range.</p>
<p>This estimator scales and translates each feature individually such
that it is in the given range on the training set, e.g. between
zero and one.</p>
<p>The transformation is given by::</p>
<pre><code>X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
X_scaled = X_std * (max - min) + min
</code></pre>
<p>where min, max = feature_range.</p>
<p>This transformation is often used as an alternative to zero mean,
unit variance scaling.</p>
<p>Read more in the :ref:<code>User Guide &lt;preprocessing_scaler&gt;</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>feature_range</code></strong> :&ensp;<code>tuple (min, max)</code>, default=<code>(0, 1)</code></dt>
<dd>Desired range of transformed data.</dd>
<dt><strong><code>copy</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>Set to False to perform inplace row normalization and avoid a
copy (if the input is already a numpy array).</dd>
<dt><strong><code>clip</code></strong> :&ensp;<code>bool</code>, default=<code>False</code></dt>
<dd>
<p>Set to True to clip transformed values of held-out data to
provided <code>feature range</code>.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.24</p>
</div>
</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>min_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>Per feature adjustment for minimum. Equivalent to
<code>min - X.min(axis=0) * self.scale_</code></dd>
<dt><strong><code>scale_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>
<p>Per feature relative scaling of the data. Equivalent to
<code>(max - min) / (X.max(axis=0) - X.min(axis=0))</code></p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>scale_</em> attribute.</p>
</div>
</dd>
<dt><strong><code>data_min_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>
<p>Per feature minimum seen in the data</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>data_min_</em></p>
</div>
</dd>
<dt><strong><code>data_max_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>
<p>Per feature maximum seen in the data</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>data_max_</em></p>
</div>
</dd>
<dt><strong><code>data_range_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>
<p>Per feature range <code>(data_max_ - data_min_)</code> seen in the data</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>data_range_</em></p>
</div>
</dd>
<dt><strong><code>n_samples_seen_</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of samples processed by the estimator.
It will be reset on new calls to fit, but increments across
<code>partial_fit</code> calls.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler
&gt;&gt;&gt; data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
&gt;&gt;&gt; scaler = MinMaxScaler()
&gt;&gt;&gt; print(scaler.fit(data))
MinMaxScaler()
&gt;&gt;&gt; print(scaler.data_max_)
[ 1. 18.]
&gt;&gt;&gt; print(scaler.transform(data))
[[0.   0.  ]
 [0.25 0.25]
 [0.5  0.5 ]
 [1.   1.  ]]
&gt;&gt;&gt; print(scaler.transform([[2, 2]]))
[[1.5 0. ]]
</code></pre>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>minmax_scale</code></dt>
<dd>Equivalent function without the estimator API.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see :ref:<code>examples/preprocessing/plot_all_scaling.py
&lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MinMax(MinMaxScaler):

    symbol = &#39;minmax&#39;
    full_name = &#39;Min-Max&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Transform features by scaling each feature to a given range (default 
        is [0,1]).

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.preprocessing._data.MinMaxScaler</li>
<li>sklearn.base.TransformerMixin</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="partycls.feature_scaling.MinMax.full_name"><code class="name">var <span class="ident">full_name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="partycls.feature_scaling.MinMax.symbol"><code class="name">var <span class="ident">symbol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="partycls.feature_scaling.MinMax.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform features by scaling each feature to a given range (default
is [0,1]).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Original features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Scaled features.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, X):
    &#34;&#34;&#34;
    Transform features by scaling each feature to a given range (default 
    is [0,1]).

    Parameters
    ----------
    X : numpy.ndarray
        Original features.

    Returns
    -------
    numpy.ndarray
        Scaled features.

    &#34;&#34;&#34;
    return self.fit_transform(X)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="partycls.feature_scaling.Robust"><code class="flex name class">
<span>class <span class="ident">Robust</span></span>
<span>(</span><span>*, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True, unit_variance=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Scale features using statistics that are robust to outliers.</p>
<p>This Scaler removes the median and scales the data according to
the quantile range (defaults to IQR: Interquartile Range).
The IQR is the range between the 1st quartile (25th quantile)
and the 3rd quartile (75th quantile).</p>
<p>Centering and scaling happen independently on each feature by
computing the relevant statistics on the samples in the training
set. Median and interquartile range are then stored to be used on
later data using the <code>transform</code> method.</p>
<p>Standardization of a dataset is a common requirement for many
machine learning estimators. Typically this is done by removing the mean
and scaling to unit variance. However, outliers can often influence the
sample mean / variance in a negative way. In such cases, the median and
the interquartile range often give better results.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
</div>
<p>Read more in the :ref:<code>User Guide &lt;preprocessing_scaler&gt;</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>with_centering</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True, center the data before scaling.
This will cause <code>transform</code> to raise an exception when attempted on
sparse matrices, because centering them entails building a dense
matrix which in common use cases is likely to be too large to fit in
memory.</dd>
<dt><strong><code>with_scaling</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True, scale the data to interquartile range.</dd>
<dt><strong><code>quantile_range</code></strong> :&ensp;<code>tuple (q_min, q_max), 0.0 &lt; q_min &lt; q_max &lt; 100.0</code>,
default=<code>(25.0, 75.0), == (1st quantile, 3rd quantile), == IQR</code></dt>
<dd>
<p>Quantile range used to calculate <code>scale_</code>.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.18</p>
</div>
</dd>
<dt><strong><code>copy</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If False, try to avoid a copy and do inplace scaling instead.
This is not guaranteed to always work inplace; e.g. if the data is
not a NumPy array or scipy.sparse CSR matrix, a copy may still be
returned.</dd>
<dt><strong><code>unit_variance</code></strong> :&ensp;<code>bool</code>, default=<code>False</code></dt>
<dd>
<p>If True, scale data so that normally distributed features have a
variance of 1. In general, if the difference between the x-values of
<code>q_max</code> and <code>q_min</code> for a standard normal distribution is greater
than 1, the dataset will be scaled down. If less than 1, the dataset
will be scaled up.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.24</p>
</div>
</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>center_</code></strong> :&ensp;<code>array</code> of <code>floats</code></dt>
<dd>The median value for each feature in the training set.</dd>
<dt><strong><code>scale_</code></strong> :&ensp;<code>array</code> of <code>floats</code></dt>
<dd>
<p>The (scaled) interquartile range for each feature in the training set.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>scale_</em> attribute.</p>
</div>
</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.preprocessing import RobustScaler
&gt;&gt;&gt; X = [[ 1., -2.,  2.],
...      [ -2.,  1.,  3.],
...      [ 4.,  1., -2.]]
&gt;&gt;&gt; transformer = RobustScaler().fit(X)
&gt;&gt;&gt; transformer
RobustScaler()
&gt;&gt;&gt; transformer.transform(X)
array([[ 0. , -2. ,  0. ],
       [-1. ,  0. ,  0.4],
       [ 1. ,  0. , -1.6]])
</code></pre>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>robust_scale</code></dt>
<dd>Equivalent function without the estimator API.</dd>
</dl>
<p><code>:class:</code>~sklearn.decomposition.PCA<code>Further removes the linear correlation across features with 'whiten=True'.</code></p>
<h2 id="notes">Notes</h2>
<p>For a comparison of the different scalers, transformers, and normalizers,
see :ref:<code>examples/preprocessing/plot_all_scaling.py
&lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;</code>.</p>
<p><a href="https://en.wikipedia.org/wiki/Median">https://en.wikipedia.org/wiki/Median</a>
<a href="https://en.wikipedia.org/wiki/Interquartile_range">https://en.wikipedia.org/wiki/Interquartile_range</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Robust(RobustScaler):

    symbol = &#39;robust&#39;
    full_name = &#39;Robust&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Scale features using statistics that are robust to outliers.

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.preprocessing._data.RobustScaler</li>
<li>sklearn.base.TransformerMixin</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="partycls.feature_scaling.Robust.full_name"><code class="name">var <span class="ident">full_name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="partycls.feature_scaling.Robust.symbol"><code class="name">var <span class="ident">symbol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="partycls.feature_scaling.Robust.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Scale features using statistics that are robust to outliers.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Original features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Scaled features.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, X):
    &#34;&#34;&#34;
    Scale features using statistics that are robust to outliers.

    Parameters
    ----------
    X : numpy.ndarray
        Original features.

    Returns
    -------
    numpy.ndarray
        Scaled features.

    &#34;&#34;&#34;
    return self.fit_transform(X)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="partycls.feature_scaling.ZScore"><code class="flex name class">
<span>class <span class="ident">ZScore</span></span>
<span>(</span><span>*, copy=True, with_mean=True, with_std=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Standardize features by removing the mean and scaling to unit variance</p>
<p>The standard score of a sample <code>x</code> is calculated as:</p>
<pre><code>z = (x - u) / s
</code></pre>
<p>where <code>u</code> is the mean of the training samples or zero if <code>with_mean=False</code>,
and <code>s</code> is the standard deviation of the training samples or one if
<code>with_std=False</code>.</p>
<p>Centering and scaling happen independently on each feature by computing
the relevant statistics on the samples in the training set. Mean and
standard deviation are then stored to be used on later data using
:meth:<code>transform</code>.</p>
<p>Standardization of a dataset is a common requirement for many
machine learning estimators: they might behave badly if the
individual features do not more or less look like standard normally
distributed data (e.g. Gaussian with 0 mean and unit variance).</p>
<p>For instance many elements used in the objective function of
a learning algorithm (such as the RBF kernel of Support Vector
Machines or the L1 and L2 regularizers of linear models) assume that
all features are centered around 0 and have variance in the same
order. If a feature has a variance that is orders of magnitude larger
that others, it might dominate the objective function and make the
estimator unable to learn from other features correctly as expected.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices by passing
<code>with_mean=False</code> to avoid breaking the sparsity structure of the data.</p>
<p>Read more in the :ref:<code>User Guide &lt;preprocessing_scaler&gt;</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>copy</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If False, try to avoid a copy and do inplace scaling instead.
This is not guaranteed to always work inplace; e.g. if the data is
not a NumPy array or scipy.sparse CSR matrix, a copy may still be
returned.</dd>
<dt><strong><code>with_mean</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True, center the data before scaling.
This does not work (and will raise an exception) when attempted on
sparse matrices, because centering them entails building a dense
matrix which in common use cases is likely to be too large to fit in
memory.</dd>
<dt><strong><code>with_std</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True, scale the data to unit variance (or equivalently,
unit standard deviation).</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>scale_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code> or <code>None</code></dt>
<dd>
<p>Per feature relative scaling of the data to achieve zero mean and unit
variance. Generally this is calculated using <code>np.sqrt(var_)</code>. If a
variance is zero, we can't achieve unit variance, and the data is left
as-is, giving a scaling factor of 1. <code>scale_</code> is equal to <code>None</code>
when <code>with_std=False</code>.</p>
<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;0.17</p>
<p><em>scale_</em></p>
</div>
</dd>
<dt><strong><code>mean_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code> or <code>None</code></dt>
<dd>The mean value for each feature in the training set.
Equal to <code>None</code> when <code>with_mean=False</code>.</dd>
<dt><strong><code>var_</code></strong> :&ensp;<code>ndarray</code> of <code>shape (n_features,)</code> or <code>None</code></dt>
<dd>The variance for each feature in the training set. Used to compute
<code>scale_</code>. Equal to <code>None</code> when <code>with_std=False</code>.</dd>
<dt><strong><code>n_samples_seen_</code></strong> :&ensp;<code>int</code> or <code>ndarray</code> of <code>shape (n_features,)</code></dt>
<dd>The number of samples processed by the estimator for each feature.
If there are no missing samples, the <code>n_samples_seen</code> will be an
integer, otherwise it will be an array of dtype int. If
<code>sample_weights</code> are used it will be a float (if no missing data)
or an array of dtype float that sums the weights seen so far.
Will be reset on new calls to fit, but increments across
<code>partial_fit</code> calls.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; data = [[0, 0], [0, 0], [1, 1], [1, 1]]
&gt;&gt;&gt; scaler = StandardScaler()
&gt;&gt;&gt; print(scaler.fit(data))
StandardScaler()
&gt;&gt;&gt; print(scaler.mean_)
[0.5 0.5]
&gt;&gt;&gt; print(scaler.transform(data))
[[-1. -1.]
 [-1. -1.]
 [ 1.  1.]
 [ 1.  1.]]
&gt;&gt;&gt; print(scaler.transform([[2, 2]]))
[[3. 3.]]
</code></pre>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>scale</code></dt>
<dd>Equivalent function without the estimator API.</dd>
</dl>
<p><code>:class:</code>~sklearn.decomposition.PCA<code>: Further removes the linear correlation across features with 'whiten=True'.</code></p>
<h2 id="notes">Notes</h2>
<p>NaNs are treated as missing values: disregarded in fit, and maintained in
transform.</p>
<p>We use a biased estimator for the standard deviation, equivalent to
<code>numpy.std(x, ddof=0)</code>. Note that the choice of <code>ddof</code> is unlikely to
affect model performance.</p>
<p>For a comparison of the different scalers, transformers, and normalizers,
see :ref:<code>examples/preprocessing/plot_all_scaling.py
&lt;sphx_glr_auto_examples_preprocessing_plot_all_scaling.py&gt;</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ZScore(StandardScaler):

    symbol = &#39;zscore&#39;
    full_name = &#39;Z-Score&#39;

    def scale(self, X):
        &#34;&#34;&#34;
        Standardize features by removing the mean and scaling to unit variance.

        Parameters
        ----------
        X : numpy.ndarray
            Original features.

        Returns
        -------
        numpy.ndarray
            Scaled features.

        &#34;&#34;&#34;
        return self.fit_transform(X)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.preprocessing._data.StandardScaler</li>
<li>sklearn.base.TransformerMixin</li>
<li>sklearn.base.BaseEstimator</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="partycls.feature_scaling.ZScore.full_name"><code class="name">var <span class="ident">full_name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="partycls.feature_scaling.ZScore.symbol"><code class="name">var <span class="ident">symbol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="partycls.feature_scaling.ZScore.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Standardize features by removing the mean and scaling to unit variance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Original features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Scaled features.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale(self, X):
    &#34;&#34;&#34;
    Standardize features by removing the mean and scaling to unit variance.

    Parameters
    ----------
    X : numpy.ndarray
        Original features.

    Returns
    -------
    numpy.ndarray
        Scaled features.

    &#34;&#34;&#34;
    return self.fit_transform(X)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="Home" href="https://htmlpreview.github.io/?https://github.com/jorisparet/partycls/blob/master/docs/partycls/index.html">
<img class="logo" src="https://raw.githubusercontent.com/jorisparet/partycls/master/logo/logo.svg" alt="Logo">
</a>
</header>
<form>
<input id="lunr-search" name="q" placeholder="🔎 Search docs" aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<!-- joris: before <h1>Index</h1> -->
<h3><em>See also:</em> <a href="https://jorisparet.github.io/partycls/docs/tutorial/">Tutorials</a></h3>
<h1><a href="index.html">API index</a></h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="partycls" href="index.html">partycls</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="partycls.feature_scaling.MaxAbs" href="#partycls.feature_scaling.MaxAbs">MaxAbs</a></code></h4>
<ul class="">
<li><code><a title="partycls.feature_scaling.MaxAbs.full_name" href="#partycls.feature_scaling.MaxAbs.full_name">full_name</a></code></li>
<li><code><a title="partycls.feature_scaling.MaxAbs.scale" href="#partycls.feature_scaling.MaxAbs.scale">scale</a></code></li>
<li><code><a title="partycls.feature_scaling.MaxAbs.symbol" href="#partycls.feature_scaling.MaxAbs.symbol">symbol</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="partycls.feature_scaling.MinMax" href="#partycls.feature_scaling.MinMax">MinMax</a></code></h4>
<ul class="">
<li><code><a title="partycls.feature_scaling.MinMax.full_name" href="#partycls.feature_scaling.MinMax.full_name">full_name</a></code></li>
<li><code><a title="partycls.feature_scaling.MinMax.scale" href="#partycls.feature_scaling.MinMax.scale">scale</a></code></li>
<li><code><a title="partycls.feature_scaling.MinMax.symbol" href="#partycls.feature_scaling.MinMax.symbol">symbol</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="partycls.feature_scaling.Robust" href="#partycls.feature_scaling.Robust">Robust</a></code></h4>
<ul class="">
<li><code><a title="partycls.feature_scaling.Robust.full_name" href="#partycls.feature_scaling.Robust.full_name">full_name</a></code></li>
<li><code><a title="partycls.feature_scaling.Robust.scale" href="#partycls.feature_scaling.Robust.scale">scale</a></code></li>
<li><code><a title="partycls.feature_scaling.Robust.symbol" href="#partycls.feature_scaling.Robust.symbol">symbol</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="partycls.feature_scaling.ZScore" href="#partycls.feature_scaling.ZScore">ZScore</a></code></h4>
<ul class="">
<li><code><a title="partycls.feature_scaling.ZScore.full_name" href="#partycls.feature_scaling.ZScore.full_name">full_name</a></code></li>
<li><code><a title="partycls.feature_scaling.ZScore.scale" href="#partycls.feature_scaling.ZScore.scale">scale</a></code></li>
<li><code><a title="partycls.feature_scaling.ZScore.symbol" href="#partycls.feature_scaling.ZScore.symbol">symbol</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
By Joris Paret and Daniele Coslovich. © Copyright 2021.
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>